{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "coursera": {
      "course_slug": "neural-networks-deep-learning",
      "graded_item_id": "XaIWT",
      "launcher_item_id": "zAgPl"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.2"
    },
    "colab": {
      "name": "1-Python Basic.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hussain0048/Python/blob/master/Basic/1_Python_Basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WZFQQORCAcS",
        "colab_type": "text"
      },
      "source": [
        "# What is mean by Python\n",
        "\n",
        "**Introduction:**\n",
        "\n",
        "Python is a very simple language, and has a very straightforward syntax. It encourages programmers to program without boilerplate (prepared) code. There are two major Python versions, Python 2 and Python 3. Python 2 and 3 are quite different. This tutorial uses Python 3, because it more semantically correct and supports newer features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYSnZoM86Lxq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/hussain0048/Python.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "beVu-1UqCAcU",
        "colab_type": "text"
      },
      "source": [
        "# 1- **Hello, World!**\n",
        "The simplest directive in Python is the \"print\" directive - it simply prints out a line (and also includes a newline, unlike in C).For example, one difference between Python 2 and 3 is the print statement. In Python 2, the \"print\" statement is not a function, and therefore it is invoked without parentheses. However, in Python 3, it is a function, and must be invoked with parentheses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF03EKpuCAcV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To print a string in Python 3, just write:\n",
        "print(\"This line will be printed.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7Cy9SPr653c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Goodbye, World!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "nhYP15aoCAcf",
        "colab_type": "text"
      },
      "source": [
        "# 2- **Indentation**\n",
        "Python uses indentation for blocks, instead of curly braces. Both tabs and spaces are supported, but the standard indentation requires standard Python code to use four spaces. For example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y1wsGi52CAch",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab438295-8652-4fba-9d9b-8aba7e195e3e"
      },
      "source": [
        "x = 1\n",
        "if x == 1:\n",
        "    # indented four spaces\n",
        "    print(\"x is 1.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x is 1.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4QYI2IoHWpL",
        "colab_type": "text"
      },
      "source": [
        "# 3 - **Variables and Types**\n",
        "Python is completely object oriented, and not \"statically typed\". You do not need to declare variables before using them, or declare their type. Every variable in Python is an object.\n",
        "\n",
        "This tutorial will go over a few basic types of variables.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AMaWX5x481qW",
        "colab_type": "text"
      },
      "source": [
        "## 3.1 Numbers\n",
        "Python supports two types of numbers - integers and floating point numbers. (It also supports complex numbers, which will not be explained in this tutorial).\n",
        "\n",
        "To define an integer, use the following syntax:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HV4itFik94rG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "myint = 7\n",
        "print(myint)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p9JGZRKCCAcq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To define a floating point number, you may use one of the following notations:\n",
        "myfloat = 7.0\n",
        "print(myfloat)\n",
        "myfloat = float(7)\n",
        "print(myfloat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCl8lMKR-WRg",
        "colab_type": "text"
      },
      "source": [
        "## 3.2- **Strings**\n",
        "Strings are defined either with a single quote or a double quotes.The difference between the two is that using double quotes makes it easy to include apostrophes (whereas these would terminate the string if using single quotes)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1DlRZn5-m4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mystring = 'hello'\n",
        "print(mystring)\n",
        "mystring = \"hello\"\n",
        "print(mystring)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehTTQE9YJF1Q",
        "colab_type": "text"
      },
      "source": [
        "# 4 -**Lists**\n",
        "Lists are very similar to arrays. They can contain any type of variable, and they can contain as many variables as you wish. Lists can also be iterated over in a very simple manner. Here is an example of how to build a list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "TvqFi8-XCAcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mylist = []\n",
        "mylist.append(1)\n",
        "mylist.append(2)\n",
        "mylist.append(3)\n",
        "print(mylist[0]) # prints 1\n",
        "print(mylist[1]) # prints 2\n",
        "print(mylist[2]) # prints 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmN5Z87UAzmf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# prints out 1,2,3\n",
        "for x in mylist:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF-GaT_VBBRz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Accessing an index which does not exist generates an exception (an error).\n",
        "mylist = [1,2,3]\n",
        "print(mylist[10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "izbM6eEUKAV-",
        "colab_type": "text"
      },
      "source": [
        "# 5- Basic Operators\n",
        "This section explains how to use basic operators in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_GxDC5VBogz",
        "colab_type": "text"
      },
      "source": [
        "## 5.1- Arithmetic Operators\n",
        "Just as any other programming languages, the addition, subtraction, multiplication, and division operators can be used with numbers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt-vctO1Kb3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "number = 1 + 2 * 3 / 4.0\n",
        "print(number)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAsBlVQ0DmXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Another operator available is the modulo (%) operator, which returns the integer remainder of the division. dividend % divisor = remainder\n",
        "remainder = 11 % 3\n",
        "print(remainder)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lYnhlcS1DtiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Using two multiplication symbols makes a power relationship.\n",
        "squared = 7 ** 2\n",
        "cubed = 2 ** 3\n",
        "print(squared)\n",
        "print(cubed)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1x8QNZN3CAdF",
        "colab_type": "text"
      },
      "source": [
        "##5.2  -Using Operators with Strings\n",
        "Python supports concatenating strings using the addition operator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNBdXxiHLfLW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fc89c894-c3de-41d0-bc3e-2c56d9219259"
      },
      "source": [
        "helloworld = \"hello\" + \" \" + \"world\"\n",
        "print(helloworld)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello world\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RkXFMVZP76K4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lotsofhellos = \"hello\" * 10\n",
        "print(lotsofhellos)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12f__4N3FDY3",
        "colab_type": "text"
      },
      "source": [
        "## 5.3- Using Operators with Lists"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZWfCifvFTXC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "even_numbers = [2,4,6,8]\n",
        "odd_numbers = [1,3,5,7]\n",
        "all_numbers = odd_numbers + even_numbers\n",
        "print(all_numbers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss60eiRpFln5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Just as in strings, Python supports forming new lists with a repeating sequence using the multiplication operator:\n",
        "print([1,2,3] * 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WNB53OY8IfG",
        "colab_type": "text"
      },
      "source": [
        "# 6- String Formatting\n",
        "\n",
        "Python uses C-style string formatting to create new, formatted strings. The \"%\" operator is used to format a set of variables enclosed in a \"tuple\" (a fixed size list), together with a format string, which contains normal text together with \"argument specifiers\", special symbols like \"%s\" and \"%d\".\n",
        "\n",
        "Let's say you have a variable called \"name\" with your user name in it, and you would then like to print(out a greeting to that user.)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_ykAt_v8egH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aef47709-8e0e-46dd-cbb7-cd84c19df4cf"
      },
      "source": [
        "# This prints out \"Hello, John!\"\n",
        "name = \"John\"\n",
        "print(\"Hello, %s!\" % name)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello, John!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcoimUu1s4MI",
        "colab_type": "text"
      },
      "source": [
        "To use two or more argument specifiers, use a tuple (parentheses):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tyfd8avhp58",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This prints out \"John is 23 years old.\"\n",
        "name = \"John\"\n",
        "age = 23\n",
        "print(\"%s is %d years old.\" % (name, age))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3epbWLyh-p4",
        "colab_type": "text"
      },
      "source": [
        "Any object which is not a string can be formatted using the %s operator as well. The string which returns from the \"repr\" method of that object is formatted as the string. For example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-QKZojviCCq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This prints out: A list: [1, 2, 3]\n",
        "mylist = [1,2,3]\n",
        "print(\"A list: %s\" % mylist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htcsGPA0iMJn",
        "colab_type": "text"
      },
      "source": [
        "Here are some basic argument specifiers you should know:\n",
        "\n",
        "%s - String (or any object with a string representation, like numbers)\n",
        "\n",
        "%d - Integers\n",
        "\n",
        "%f - Floating point numbers\n",
        "\n",
        "%.<number of digits>f - Floating point numbers with a fixed amount of digits to the right of the dot.\n",
        "\n",
        "%x/%X - Integers in hex representation (lowercase/uppercase)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdpTOYOlCAdP",
        "colab_type": "text"
      },
      "source": [
        "# 7-**Basic String Operations**\n",
        "Strings are bits of text. They can be defined as anything between quotes:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5uHKjQWZ0WV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "astring2 = 'Hello world!'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r_VGeM-W6ADp",
        "colab_type": "text"
      },
      "source": [
        "As you can see, the first thing you learned was printing a simple sentence. This sentence was stored by Python as a string. However, instead of immediately printing strings out, we will explore the various things you can do to them. You can also use single quotes to assign a string. However, you will face problems if the value to be assigned itself contains single quotes.For example to assign the string in these bracket(single quotes are ' ') you need to use double quotes only like this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RP9VUw8v6CKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(\"single quotes are ' '\")\n",
        "print(len(astring))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMZsbrdxMsk_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring.index(\"o\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jib_dHP4MnL8",
        "colab_type": "text"
      },
      "source": [
        "That prints out 4, because the location of the first occurrence of the letter \"o\" is 4 characters away from the first character. Notice how there are actually two o's in the phrase - this method only recognizes the first.\n",
        "\n",
        "But why didn't it print out 5? Isn't \"o\" the fifth character in the string? To make things more simple, Python (and most other programming languages) start things at 0 instead of 1. So the index of \"o\" is 4."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VZPHeAVM7W-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring.count(\"l\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJuKccPBNkDH",
        "colab_type": "text"
      },
      "source": [
        "For those of you using silly fonts, that is a lowercase L, not a number one. This counts the number of l's in the string. Therefore, it should print 3."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zntMPysON5Ts",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring[3:7])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHo45-BfN-wE",
        "colab_type": "text"
      },
      "source": [
        "This prints a slice of the string, starting at index 3, and ending at index 6. But why 6 and not 7? Again, most programming languages do this - it makes doing math inside those brackets easier.\n",
        "\n",
        "If you just have one number in the brackets, it will give you the single character at that index. If you leave out the first number but keep the colon, it will give you a slice from the start to the number you left in. If you leave out the second number, it will give you a slice from the first number to the end.\n",
        "\n",
        "You can even put negative numbers inside the brackets. They are an easy way of starting at the end of the string instead of the beginning. This way, -3 means \"3rd character from the end\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2fVOhDtOOVj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring[3:7:2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JPolHSEOSqH",
        "colab_type": "text"
      },
      "source": [
        "This prints the characters of string from 3 to 7 skipping one character. This is extended slice syntax. The general form is [start:stop:step]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1m8tU3n8OdSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring[3:7])\n",
        "print(astring[3:7:1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQp54I1kOneQ",
        "colab_type": "text"
      },
      "source": [
        "Note that both of them produce same output\n",
        "\n",
        "There is no function like strrev in C to reverse a string. But with the above mentioned type of slice syntax you can easily reverse a string like this"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4BaWsS0Osab",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0aacb32-f36f-4848-d408-8cd43f12897e"
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring[::-1])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!dlrow olleH\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXGsuQmhO1ND",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring.upper())\n",
        "print(astring.lower())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AFCFOpXO_Cr",
        "colab_type": "text"
      },
      "source": [
        "hese make a new string with all letters converted to uppercase and lowercase, respectively."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQGbPPncPA30",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "print(astring.startswith(\"Hello\"))\n",
        "print(astring.endswith(\"asdfasdfasdf\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v5Rg7hGqPNMO",
        "colab_type": "text"
      },
      "source": [
        "This is used to determine whether the string starts with something or ends with something, respectively. The first one will print True, as the string starts with \"Hello\". The second one will print False, as the string certainly does not end with \"asdfasdfasdf\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLLTo7DRPBIT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "astring = \"Hello world!\"\n",
        "afewwords = astring.split(\" \")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTX2uBXKPZUx",
        "colab_type": "text"
      },
      "source": [
        "This splits the string into a bunch of strings grouped together in a list. Since this example splits at a space, the first item in the list will be \"Hello\", and the second will be \"world!\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTe0Qqi3CAeA",
        "colab_type": "text"
      },
      "source": [
        "# 8- **Conditions**\n",
        "Python uses boolean variables to evaluate conditions. The boolean values True and False are returned when an expression is compared or evaluated. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kq4Ho1l8Ksjt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 2\n",
        "print(x == 2) # prints out True\n",
        "print(x == 3) # prints out False\n",
        "print(x < 3) # prints out True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_FZLht0akQz",
        "colab_type": "text"
      },
      "source": [
        "Notice that variable assignment is done using a single equals operator \"=\", whereas comparison between two variables is done using the double equals operator \"==\". The \"not equals\" operator is marked as \"!=\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VwPfoQSS4Av",
        "colab_type": "text"
      },
      "source": [
        "## 8.1 - Boolean operators\n",
        "The \"and\" and \"or\" boolean operators allow building complex boolean expressions, for example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5DYf8Quv_PxR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"John\"\n",
        "age = 23\n",
        "if name == \"John\" and age == 23:\n",
        "    print(\"Your name is John, and you are also 23 years old.\")\n",
        "\n",
        "if name == \"John\" or name == \"Rick\":\n",
        "    print(\"Your name is either John or Rick.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrZx-6XeziR0",
        "colab_type": "text"
      },
      "source": [
        "## 8.2 The \"in\" operator\n",
        "The \"in\" operator could be used to check if a specified object exists within an iterable object container, such as a list:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_q87nKz4zxr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "name = \"John\"\n",
        "if name in [\"John\", \"Rick\"]:\n",
        "    print(\"Your name is either John or Rick.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnWR24dBHGty",
        "colab_type": "text"
      },
      "source": [
        "Python uses indentation to define code blocks, instead of brackets. The standard Python indentation is 4 spaces, although tabs and any other space size will work, as long as it is consistent. Notice that code blocks do not need any termination.\n",
        "\n",
        "Here is an example for using Python's \"if\" statement using code blocks:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzkWkVZEbrpw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "statement = False\n",
        "another_statement = True\n",
        "if statement is True:\n",
        "    # do something\n",
        "    pass\n",
        "elif another_statement is True: # else if\n",
        "    # do something else\n",
        "    pass\n",
        "else:\n",
        "    # do another thing\n",
        "    pass"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03BGhfi0b5Tx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = 2\n",
        "if x == 2:\n",
        "    print(\"x equals two!\")\n",
        "else:\n",
        "    print(\"x does not equal to two.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3BFbDJjCcACN",
        "colab_type": "text"
      },
      "source": [
        "A statement is evaulated as true if one of the following is correct: 1. The \"True\" boolean variable is given, or calculated using an expression, such as an arithmetic comparison. 2. An object which is not considered \"empty\" is passed.\n",
        "\n",
        "Here are some examples for objects which are considered as empty: 1. An empty string: \"\" 2. An empty list: [] 3. The number zero: 0 4. The false boolean variable: False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sq0XpVN0UZ7",
        "colab_type": "text"
      },
      "source": [
        "## 8.3 The 'is' operator\n",
        "Unlike the double equals operator \"==\", the \"is\" operator does not match the values of the variables, but the instances themselves. For example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ2nyHRV0dnH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = [1,2,3]\n",
        "y = [1,2,3]\n",
        "print(x == y) # Prints out True\n",
        "print(x is y) # Prints out False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUnd-y071Epv",
        "colab_type": "text"
      },
      "source": [
        "## 8.5- Precision-Recall Curve\n",
        "\n",
        "Precision and Recall helps a lot in case of imbalanced datasets. Plotting different values of precision vs recall by setting different thresholds helps in evaluating the performance of the model better in case of imbalance classes. It does not take into consideration true negatives as it's majority class and True positives represent minority class which has quite a few occurrences.\n",
        "\n",
        "Note: It's restricted to binary classification tasks.\n",
        "\n",
        "The below plot is Precision-Recall Curve for SVM on the unbalanced dataset test set.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LsBaFnzd1U_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve, auc,average_precision_score\n",
        "\n",
        "decision_function = svc.decision_function(X_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, decision_function)\n",
        "acc = svc.score(X_test, Y_test)\n",
        "p_auc = auc(recall, precision)\n",
        "\n",
        "with plt.style.context(('ggplot', 'seaborn')):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.scatter(recall, precision, c='blue')\n",
        "    plt.plot(recall, precision, label=\"Accuray:%.2f, AUC:%.2f\" % (acc, p_auc), linewidth=2, c='red')\n",
        "    plt.hlines(0.5,0.0,1.0, linestyle='dashed', colors=['orange'])\n",
        "    plt.xlabel(\"Recall (Sensitivity)\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title('Precision Recall Curve')\n",
        "    plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNRf7x0tI5tQ",
        "colab_type": "text"
      },
      "source": [
        "Precision-recall curve totally crashes if our model is not performing well in case of imbalanced dataset. Notice that AUC in case of precison recall curve is 50% and whereas AUC with ROC curve was around 90%. ROC curves sometimes give optimistic results hence its better to consider precision recall curves as well in case of imbalanced datasets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLHoK7AJI79P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "outputId": "51acd3ca-acd8-4888-feb5-98cdbb1cb0df"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid = GridSearchCV(SVC(probability=True),param_grid = {'gamma': ['auto', 'scale'], 'C': [1.0, 0.1, 0.01, 10.0]}, cv=5)\n",
        "grid.fit(X, Y)\n",
        "print('Best Parameters                                        : ',grid.best_params_)\n",
        "print('Best Score                                             : ',grid.best_score_)\n",
        "\n",
        "decision_function = grid.best_estimator_.decision_function(X_test)\n",
        "precision, recall, thresholds = precision_recall_curve(Y_test, decision_function)\n",
        "\n",
        "print('Precision                                              : ', precision)\n",
        "print('Recall                                                 : ', recall)\n",
        "print('Different Thresholds For Calculating Precision, Recall : ', thresholds)\n",
        "print('Classification Report                                  : ')\n",
        "print(classification_report(Y_test, grid.best_estimator_.predict(X_test)))\n",
        "\n",
        "acc = grid.best_estimator_.score(X_test, Y_test)\n",
        "p_auc = auc(recall, precision)\n",
        "ap = average_precision_score(Y_test, grid.predict_proba(X_test)[:,1])\n",
        "\n",
        "with plt.style.context(('ggplot', 'seaborn')):\n",
        "    plt.figure(figsize=(8,6))\n",
        "    plt.scatter(recall, precision, c='blue')\n",
        "    plt.plot(recall, precision, label=\"Accuracy:%.2f, AUC:%.2f, Average Precision %.2f\" % (acc, p_auc, ap), linewidth=2, c='red')\n",
        "    plt.xlabel(\"Recall (Sensitivity)\")\n",
        "    plt.ylabel(\"Precision\")\n",
        "    plt.title('Precision Recall Curve')\n",
        "    plt.legend(loc='best');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Parameters                                        :  {'C': 1.0, 'gamma': 'auto'}\n",
            "Best Score                                             :  0.9719999999999999\n",
            "Precision                                              :  [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
            " 1. 1. 1.]\n",
            "Recall                                                 :  [1.   0.98 0.96 0.94 0.92 0.9  0.88 0.86 0.84 0.82 0.8  0.78 0.76 0.74\n",
            " 0.72 0.7  0.68 0.66 0.64 0.62 0.6  0.58 0.56 0.54 0.52 0.5  0.48 0.46\n",
            " 0.44 0.42 0.4  0.38 0.36 0.34 0.32 0.3  0.28 0.26 0.24 0.22 0.2  0.18\n",
            " 0.16 0.14 0.12 0.1  0.08 0.06 0.04 0.02 0.  ]\n",
            "Different Thresholds For Calculating Precision, Recall :  [0.77 0.83 0.83 0.84 0.84 1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
            " 1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.   1.\n",
            " 1.07 1.07 1.08 1.14 1.25 1.3  1.31 1.38 1.42 1.44 1.46 1.48 1.7  1.77\n",
            " 2.12 2.24 2.3  2.33 2.42 2.57 2.71 3.17]\n",
            "Classification Report                                  : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        50\n",
            "           1       1.00      1.00      1.00        50\n",
            "\n",
            "    accuracy                           1.00       100\n",
            "   macro avg       1.00      1.00      1.00       100\n",
            "weighted avg       1.00      1.00      1.00       100\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05Gq2A7BCAeX",
        "colab_type": "text"
      },
      "source": [
        "## 8.6 Log Loss (Logistic Loss or Cross-Entropy Loss)\n",
        "Log loss refers to the negative log-likelihood of true labels predicted by the classifier. It's a cost function whose output classifiers try to minimize while updating weights of the model.\n",
        "\n",
        "log_loss=−y∗log(y′)−(1−y)∗log(1−y′)\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbZKdf9heXoT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import log_loss\n",
        "\n",
        "X, Y = datasets.make_classification(n_samples= 500)\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, stratify=Y)\n",
        "print('Train/Test Sizes : ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "\n",
        "grid = GridSearchCV(SVC(probability=True),param_grid = {'C': [1.0, 0.1, 0.01, 10.0,]}, scoring=\"neg_log_loss\", cv=5)\n",
        "grid.fit(X, Y)\n",
        "\n",
        "print('Best Parameters : ',grid.best_params_)\n",
        "#print('Test Log Loss : %.3f'%grid.best_estimator_.score(X_test, Y_test))\n",
        "#print('Train Log Loss : %.3f'%grid.best_estimator_.score(X_train, Y_train))\n",
        "print('Test Log Loss   : %.3f'%log_loss(Y_test, grid.best_estimator_.predict_proba(X_test)))\n",
        "print('Train Log Loss  : %.3f'%log_loss(Y_train, grid.best_estimator_.predict_proba(X_train)))\n",
        "Y_preds = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWCpBVwViJPO",
        "colab_type": "text"
      },
      "source": [
        "## 8.7. Zero One Classification Loss \n",
        " It returns a number of misclassifications or a fraction of misclassifications. It accepts normalize parameter whose value if set True then returns a fraction of misclassifications else if set to False then it returns misclassifications.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OpwvTn_qDLZn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import zero_one_loss\n",
        "\n",
        "print('Number of Misclassificied Examples   : ',zero_one_loss(Y_test, Y_preds, normalize=False))\n",
        "print('Fraction of Misclassificied Examples : ',zero_one_loss(Y_test, Y_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6as5LRNgjTng",
        "colab_type": "text"
      },
      "source": [
        "## 8.8 Balanced Accuracy Score\n",
        "It returns an average of recall of each class in classification problem. It's useful to deal with imbalanced datasets.\n",
        "\n",
        "It has parameter adjusted which when set True results are adjusted for a chance so that the random performing model would get a score of 0 and perfect performance will get 1.0."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ld1_nNE_mDcW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import balanced_accuracy_score\n",
        "\n",
        "print('Balanced Accuracy          : ',balanced_accuracy_score(Y_test, Y_preds))\n",
        "print('Balanced Accuracy Adjusted : ',balanced_accuracy_score(Y_test, Y_preds, adjusted=True))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "yN3QOkmDCAed",
        "colab_type": "text"
      },
      "source": [
        "## 8.9 -Brier Loss\n",
        "It computes squared differences between the actual labels of class and predicted probability by model. It should be as low as possible for good performance. It’s for binary classification problems only. It by defaults takes 1 as positive class hence if one needs to consider 0 as a positive class then one can use the pos_label parameter as below.\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nKMoGy7D4KXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " from sklearn.metrics import brier_score_loss\n",
        "\n",
        "print('Brier Loss                       : ',brier_score_loss(Y_test, grid.predict_proba(X_test)[:, 1]))\n",
        "print('Brier Loss (0 as Positive Class) : ', brier_score_loss(Y_test, grid.predict_proba(X_test)[:, 0], pos_label=0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZO6HAiq04ZKr",
        "colab_type": "text"
      },
      "source": [
        "## 8.10 F-Beta Score\n",
        "F-Beta score refers to weighted average of precision and recall based on the value of the beta parameter provided. If beta < 1 then it lends more weight to precision, while beta > 1 lends more weight to recall. It has the best value of 1.0 and the worst 0.0.\n",
        "\n",
        "It has a parameter called average which is required for multiclass problems. It accepts values [None, 'binary'(default), 'micro', 'macro', 'samples', 'weighted']. If None is specified then the score for each class is returned else average as per parameter is returned in a multiclass problem.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "woRGjqgH4lTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "print('Fbeta Favouring Precision : ', fbeta_score(Y_test, Y_preds, beta=0.5))\n",
        "print('Fbeta Favouring Recall    : ' ,fbeta_score(Y_test, Y_preds, beta=2.0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xH8Qq6J72il",
        "colab_type": "text"
      },
      "source": [
        "## 8.11  Hamming Loss\n",
        "\n",
        "it returns fraction of labels misclassified.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn6-jer48jeF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import hamming_loss\n",
        "\n",
        "print('Hamming Loss : ', hamming_loss(Y_test, Y_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J75Rv0fr8qWA",
        "colab_type": "text"
      },
      "source": [
        "# Regression Metrics\n",
        "We'll now introduce model evaluation metrics for regression tasks. We'll start with loading the Boston dataset available in scikit-learn for our purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bDoYPVl48x_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#X, Y = datasets.make_regression(n_samples=200, n_features=20, )\n",
        "boston = datasets.load_boston()\n",
        "X, Y = boston.data, boston.target\n",
        "print('Dataset Size : ', X.shape, Y.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLz12BeRLclF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We'll be splitting a dataset into train/test sets with 80% for a train set and 20% for the test set.\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, random_state=1, )\n",
        "print('Train/Test Size : ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeqodSRRLrBB",
        "colab_type": "text"
      },
      "source": [
        "We'll now initialize a simple LinearSVR model and train it on the train dataset. We'll then check its performance by evaluating various regression metrics provided by scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rp-Y3kMLyBP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.svm import LinearSVR\n",
        "svr = LinearSVR()\n",
        "svr.fit(X_train, Y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-Ubl4dFR1IG",
        "colab_type": "text"
      },
      "source": [
        "## 1- R2  (Coefficient Of Determination)\n",
        "The coefficient of  R2  is defined as  (1−u/v) .\n",
        "\n",
        "u=((ytrue−ypred)2).sum() \n",
        "\n",
        "v=((ytrue−ytrue.sum())2).sum() \n",
        "\n",
        "The best possible score is 1.0 and it can be negative as well if the model is performing badly. A model that outputs constant prediction for each input will have a score of 0.0.\n",
        "\n",
        "Note: The majority of the regression model's score() method outputs this metric which is quite different from MSE(mean square error). Hence both should not be confused."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1UlaNus5S00W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import r2_score\n",
        "Y_preds = svr.predict(X_test)\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])\n",
        "print('Test R^2     : %.3f'%r2_score(Y_test, Y_preds))\n",
        "print('Test R^2     : %.3f'%svr.score(X_test, Y_test))\n",
        "print('Training R^2 : %.3f'%svr.score(X_train, Y_train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YP-qHfRMYQ3",
        "colab_type": "text"
      },
      "source": [
        "Below we are doing grid search through various values of parameter C of LinearSVR and using r2 as an evaluation metric whose value will be optimized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KAwsGn2wMawr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = GridSearchCV(LinearSVR(),param_grid = {'C': [1.0, 0.1, 0.01, 10.0,]}, scoring=\"r2\", cv=5)\n",
        "grid.fit(X, Y)\n",
        "\n",
        "print('Best Parameters : ',grid.best_params_)\n",
        "print('Best Score      : ',grid.best_score_)\n",
        "print('Test R^2        : %.3f'%r2_score(Y_test, grid.best_estimator_.predict(X_test)))\n",
        "print('Test R^2        : %.3f'%grid.best_estimator_.score(X_test, Y_test))\n",
        "print('Training R^2    : %.3f'%grid.best_estimator_.score(X_train, Y_train))\n",
        "\n",
        "Y_preds = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2MOQ4EQSOR3",
        "colab_type": "text"
      },
      "source": [
        "## 2 Mean Absolute Error\n",
        "\n",
        "Mean absolute error is a simple sum of the absolute difference between actual and predicted target value divided by a number of samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH3RPskMSFz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_absolute_error\n",
        "print('Test MAE  : %.3f'%mean_absolute_error(Y_test, Y_preds))\n",
        "print('Train MAE : %.3f'%mean_absolute_error(Y_train, svr.predict(X_train)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "za4dxOJ7NEJA",
        "colab_type": "text"
      },
      "source": [
        "Below we are doing grid search through various values of parameter C of LinearSVR and using neg_mean_absolute_error as an evaluation metric whose value will be optimized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4w7AC6NIwy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = GridSearchCV(LinearSVR(),param_grid = {'C': [1.0, 0.1, 0.01, 10.0,]}, scoring=\"neg_mean_absolute_error\", cv=5)\n",
        "grid.fit(X, Y)\n",
        "\n",
        "print('Best Parameters : ',grid.best_params_)\n",
        "print('Test MAE        : %.3f'%mean_absolute_error(Y_test, grid.best_estimator_.predict(X_test)))\n",
        "print('Train MAE       : %.3f'%mean_absolute_error(Y_train, grid.best_estimator_.predict(X_train)))\n",
        "Y_preds = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63Bpx7DCS_Hg",
        "colab_type": "text"
      },
      "source": [
        "## 3- Mean Squared Error\n",
        "Mean Squared Error loss function simple sum of the squared difference between actual and predicted value divided by a number of samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRZyu778bBmb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "\n",
        "print('Test MSE  : %.3f'%mean_squared_error(Y_test, Y_preds))\n",
        "print('Train MSE : %.3f'%mean_squared_error(Y_train, svr.predict(X_train)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9gHww-SyNjdA",
        "colab_type": "text"
      },
      "source": [
        "Below we are doing grid search through various values of parameter C of LinearSVR and using neg_mean_squared_error as an evaluation metric whose value will be optimized."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn_YNHTuNpyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid = GridSearchCV(LinearSVR(),param_grid = {'C': [1.0, 0.1, 0.01, 10.0,]}, scoring=\"neg_mean_squared_error\", cv=5)\n",
        "grid.fit(X, Y)\n",
        "\n",
        "print('Best Parameters : ',grid.best_params_)\n",
        "print('Test MSE        : %.3f'%mean_squared_error(Y_test, grid.best_estimator_.predict(X_test)))\n",
        "print('Train MSE       : %.3f'%mean_squared_error(Y_train, grid.best_estimator_.predict(X_train)))\n",
        "Y_preds = grid.best_estimator_.predict(X_test)\n",
        "\n",
        "print(Y_preds[:10])\n",
        "print(Y_test[:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na4QkhBbbKUT",
        "colab_type": "text"
      },
      "source": [
        "## 4 Mean Squared Log Error¶\n",
        "\n",
        "It can not be used when target contains negative values/predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4jiDFJnbJAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "print(mean_squared_log_error(Y_test, Y_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZfpXMFLbiDQ",
        "colab_type": "text"
      },
      "source": [
        "## 5 Median Absolute Error"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXpM8bIebn7-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import median_absolute_error\n",
        "\n",
        "print('Median Absolute Error : ', median_absolute_error(Y_test, Y_preds))\n",
        "print('Median Absolute Error : ', np.median(np.abs(Y_test - Y_preds)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rkHO3kcibyVR",
        "colab_type": "text"
      },
      "source": [
        "## 6 Explained Variance Score\n",
        "It returns the explained variance regression score. The best value is 1.0 and fewer values refer to a bad model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MJthSM_lcDZ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import explained_variance_score\n",
        "\n",
        "print('Explained Variance Score : ', explained_variance_score(Y_test, Y_preds))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOU8Vi0BccAJ",
        "colab_type": "text"
      },
      "source": [
        "##7 Residual Error\n",
        "It returns the max of the difference between actual values and the predicted value of all samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oH7k634FcuyQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import max_error\n",
        "\n",
        "print('Maximum Residual Error : ', max_error(Y_test, Y_preds))\n",
        "print('Maximum Residual Error : ', max_error([1,2,3,4], [1,2,3.5,7])) ## here 4th sample has highest difference\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mdpo2iWxdBaY",
        "colab_type": "text"
      },
      "source": [
        "# Clustering Metrics\n",
        "We'll now introduce evaluation metrics for unsupervised learning - clustering tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ixgNi1OX0Em",
        "colab_type": "text"
      },
      "source": [
        "## 1-Adjusted Rand Score\n",
        "\n",
        "Clustering algorithms return cluster labels for each cluster specified but it might not return in the same sequence as original labels. It might happen that in the original dataset some class has samples labeled as 1 and in predictions by cluster, an algorithm can label it as other than 1.\n",
        "\n",
        "We'll use the IRIS dataset and KMeans for explanation purposes.We'll even plot results to show the difference. We'll how accuracy will improve once we use adjusted_rand_score as an evaluation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPRXvkRfdHcy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans, MeanShift\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score, adjusted_rand_score, confusion_matrix\n",
        "\n",
        "iris = load_iris()\n",
        "X, Y = iris.data, iris.target\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.80, test_size=0.20, stratify=Y, random_state=12)\n",
        "print('Train/Test Sizes  : ', X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)\n",
        "\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(X_train, Y_train)\n",
        "Y_preds = kmeans.predict(X_test)\n",
        "\n",
        "#print(Y_test, Y_preds)\n",
        "print('Confusion Matrix : ')\n",
        "print(confusion_matrix(Y_test, Y_preds))\n",
        "print('Accuracy of Model : %.3f'%accuracy_score(Y_test, Y_preds))\n",
        "print('Adjusted Accuracy : %.3f'%adjusted_rand_score(Y_test, Y_preds))\n",
        "\n",
        "with plt.style.context(('ggplot', 'seaborn')):\n",
        "    plt.figure(figsize=(10,4))\n",
        "    plt.subplot(121)\n",
        "    plt.scatter(X_test[: , 1], X_test[:, 2], c=Y_test, cmap = plt.cm.viridis)\n",
        "    plt.xlabel(iris.feature_names[1])\n",
        "    plt.ylabel(iris.feature_names[2])\n",
        "    plt.title('Y Original')\n",
        "    plt.subplot(122)\n",
        "    plt.scatter(X_test[: , 1], X_test[:, 2], c=Y_preds, cmap = plt.cm.viridis)\n",
        "    plt.xlabel(iris.feature_names[1])\n",
        "    plt.ylabel(iris.feature_names[2])\n",
        "    plt.title('Y Predicted');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iP6m2bJhYUAB",
        "colab_type": "text"
      },
      "source": [
        "##2-Custom Scoring Function\n",
        "Users can also define their own scoring function if their scoring function is not available in built-in scoring functions of sklearn. In GridSearchCV and cross_val_score, one can provide object which has __call__ method or function to scoring parameter. Object or function both need to accept estimator object, test features(X) and target(Y) as input and return float.\n",
        "\n",
        "Below we are defining RMSE (Root Mean Squared Error) as a class and as a function as well. We'll then use it in cross_val_score() to check performance also compares it's value with negative of neg_mean_squared_error."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OH6uO_UuYnWn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RootMeanSquareError(object):\n",
        "    def __call__(self, model, X, Y):\n",
        "        Y_preds = model.predict(X)\n",
        "        return np.sqrt(((Y - Y_preds)**2).mean())\n",
        "\n",
        "def rootMeanSquareError(model, X, Y):\n",
        "    Y_preds = model.predict(X)\n",
        "    return np.sqrt(((Y - Y_preds)**2).mean())\n",
        "\n",
        "lsvr = LinearSVR(random_state=1)\n",
        "print('Cross Val Score Using Object                                     : ',cross_val_score(lsvr, X, Y, scoring=RootMeanSquareError()))\n",
        "print('Cross Val Score Using Function                                   : ', cross_val_score(lsvr, X, Y, scoring=rootMeanSquareError))\n",
        "print('Cross Val Score Using Negative Mean Squared Error                : ', -1*cross_val_score(lsvr, X, Y, scoring='neg_mean_squared_error'))\n",
        "print('Cross Val Score Using Square Root of Negative Mean Squared Error : ', np.sqrt(-1*cross_val_score(lsvr, X, Y, scoring='neg_mean_squared_error')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie2fvr6tYxc5",
        "colab_type": "text"
      },
      "source": [
        "Below are list of scikit-learn builtin functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0Hhr4nJYzxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('List of Inbuilt Scorers : ')\n",
        "sklearn.metrics.SCORERS"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm7uTbEWCAei",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "Learn Python\n",
        "https://www.learnpython.org/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LvqfD4BCAei",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}